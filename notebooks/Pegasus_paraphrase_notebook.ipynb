{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pegasus Paraphrase\n",
    "PEGASUS is a standard Transformer encoder-decoder. PEGASUS uses GSG to pre-train a Transformer encoder-decoder on large corpora of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BEAM_NUM = 10\n",
    "RETURN_SEQ_NUM = 10\n",
    "PEGASUS_PRETRAINED_MODEL = 'tuner007/pegasus_paraphrase'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pegasus_tokenizer = PegasusTokenizer.from_pretrained(PEGASUS_PRETRAINED_MODEL)\n",
    "pegasus_model = PegasusForConditionalGeneration.from_pretrained(PEGASUS_PRETRAINED_MODEL).to(torch_device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTUAL TEXT:  Can you recommed some upscale restaurants in Newyork?\n",
      "Is it possible to recommed some upscale restaurants in New York?\n",
      "Is it possible to remake some upscale restaurants in New York?\n",
      "Is there any upscale restaurants in New York?\n",
      "Is it possible to recommed upscale restaurants in New York?\n",
      "Is it possible to remake upscale restaurants in New York?\n",
      "Is it possible to recommed some upscale restaurants in NewYork?\n",
      "Can you remake some upscale restaurants in New York?\n",
      "Are you able to recommed some upscale restaurants in New York?\n",
      "Are there any upscale restaurants in New York?\n",
      "Is there any upscale restaurants in New York that you can remake?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_text = \"Can you recommed some upscale restaurants in Newyork?\"\n",
    "\n",
    "\n",
    "batch = pegasus_tokenizer([input_text], truncation=True, padding='longest', max_length=60, return_tensors=\"pt\").to(torch_device)\n",
    "translated = pegasus_model.generate(**batch, max_length=60, num_beams=BEAM_NUM, num_return_sequences=RETURN_SEQ_NUM, temperature=1.5)\n",
    "tgt_text = pegasus_tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "\n",
    "print(\"ACTUAL TEXT: \",input_text)\n",
    "for each_text in tgt_text:\n",
    "    print(each_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTUAL TEXT:  The quick brown fox jumps over the lazy dog.\n",
      "The dog is lazy and the quick brown fox jumps over it.\n",
      "The brown fox jumps over the lazy dog.\n",
      "The brown fox is jumping over the lazy dog.\n",
      "A quick brown fox jumps over a lazy dog.\n",
      "The dog is lazy and the quick brown fox jumps over him.\n",
      "The dog is lazy and the brown fox jumps over it.\n",
      "The dog is lazy and the fox jumps over it.\n",
      "The fox jumps over the dog.\n",
      "The fox jumps over the lazy dog.\n",
      "The dog is lazy and the brown fox jumps over him.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "batch = pegasus_tokenizer([input_text], truncation=True, padding='longest', max_length=60, return_tensors=\"pt\").to(torch_device)\n",
    "translated = pegasus_model.generate(**batch, max_length=60, num_beams=BEAM_NUM, num_return_sequences=RETURN_SEQ_NUM, temperature=1.5)\n",
    "tgt_text = pegasus_tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "\n",
    "print(\"ACTUAL TEXT: \",input_text)\n",
    "for each_text in tgt_text:\n",
    "    print(each_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Citation\n",
    "        @misc{ma2019nlpaug,\n",
    "        title={NLP Augmentation},\n",
    "        author={Edward Ma},\n",
    "        howpublished={https://github.com/makcedward/nlpaug},\n",
    "        year={2019}\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
